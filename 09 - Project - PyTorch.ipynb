{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "09 - Project - PyTorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f076dd2d6db4ca2a05dd9fcd43cc9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7fadbd5e93fe468d9e89eb02b34904c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e7eeb0a7746142cba53a54f28c16e86c",
              "IPY_MODEL_edfab5dfe1504ba5ac91ab0f89cb0139",
              "IPY_MODEL_d76942abe8c7408ea2b979a95d879fb7"
            ]
          }
        },
        "7fadbd5e93fe468d9e89eb02b34904c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7eeb0a7746142cba53a54f28c16e86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8faa687c9d9c4583a82200a515b43648",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af6eb3022bf14fd286d3bf0c6a0addd7"
          }
        },
        "edfab5dfe1504ba5ac91ab0f89cb0139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9873ec82bbd84ebd8b0f721707ab4522",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3dbdf640b094fba98414dcceb14339b"
          }
        },
        "d76942abe8c7408ea2b979a95d879fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac96a2e5ef7b4b749230cae14308880a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 54472418.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8df35de0ce44ae3a0b0fb74ed84faff"
          }
        },
        "8faa687c9d9c4583a82200a515b43648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af6eb3022bf14fd286d3bf0c6a0addd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9873ec82bbd84ebd8b0f721707ab4522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3dbdf640b094fba98414dcceb14339b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac96a2e5ef7b4b749230cae14308880a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8df35de0ce44ae3a0b0fb74ed84faff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adel-nouar/ML_with_Rune/blob/main/09%20-%20Project%20-%20PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef5edb03"
      },
      "source": [
        "### Step 1: Install Torch\n",
        "- Execute the following cell which will install **torch** and **torchvision**"
      ],
      "id": "ef5edb03"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c19e8755",
        "outputId": "040ffd53-a9e8-4146-a495-bd2593fe12bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torchvision"
      ],
      "id": "c19e8755",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b8bc9a2"
      },
      "source": [
        "### Step 2: Import libraries"
      ],
      "id": "6b8bc9a2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fca19d9d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "id": "fca19d9d",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb3a4ae5"
      },
      "source": [
        "### Step 3: Download the CIFAR10 dataset\n",
        "- Excute the cell below"
      ],
      "id": "cb3a4ae5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73c6e5bb",
        "outputId": "53e80ed9-2c25-4b1b-c230-4b1564c6d05f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "3f076dd2d6db4ca2a05dd9fcd43cc9ec",
            "7fadbd5e93fe468d9e89eb02b34904c6",
            "e7eeb0a7746142cba53a54f28c16e86c",
            "edfab5dfe1504ba5ac91ab0f89cb0139",
            "d76942abe8c7408ea2b979a95d879fb7",
            "8faa687c9d9c4583a82200a515b43648",
            "af6eb3022bf14fd286d3bf0c6a0addd7",
            "9873ec82bbd84ebd8b0f721707ab4522",
            "b3dbdf640b094fba98414dcceb14339b",
            "ac96a2e5ef7b4b749230cae14308880a",
            "c8df35de0ce44ae3a0b0fb74ed84faff"
          ]
        }
      },
      "source": [
        "data_path = 'downloads/'\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
      ],
      "id": "73c6e5bb",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to downloads/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f076dd2d6db4ca2a05dd9fcd43cc9ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting downloads/cifar-10-python.tar.gz to downloads/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd1bd0ca"
      },
      "source": [
        "### Step 4: Explore the dataset\n",
        "- See the type of **cifar10**\n",
        "- Get the length of **cifar10**\n",
        "- Assign image and label of **cifar10** at index 1000\n",
        "- Get the class name of label\n",
        "    - HINT: Use **cifar10.classes[label]** to get the name"
      ],
      "id": "cd1bd0ca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a18c1717",
        "outputId": "1cc3f83d-9426-4678-f599-baf844da80f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(cifar10)"
      ],
      "id": "a18c1717",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.cifar.CIFAR10"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5494a539",
        "outputId": "36d4ce66-536d-400b-d451-fae3f47afef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(cifar10), len(cifar10_val)"
      ],
      "id": "5494a539",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f74c3dc"
      },
      "source": [
        "img, label = cifar10[1000]"
      ],
      "id": "6f74c3dc",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cef4468",
        "outputId": "e01869f8-aa38-4894-e562-bc471fd5dcdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "cifar10.classes[label]"
      ],
      "id": "8cef4468",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'truck'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65639015"
      },
      "source": [
        "### Step 5: Visualize the image\n",
        "- Use **matplotlib** to visuazlize image\n",
        "    - HINT: just use **plt.imshow(...)**"
      ],
      "id": "65639015"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dbf5fa3",
        "outputId": "8bf2f674-3f9c-4d17-d111-da42b2b8f369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.imshow(img)"
      ],
      "id": "3dbf5fa3",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9cde654b50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8005d75d"
      },
      "source": [
        "### Step 6: Transform images\n",
        "- We need to convert the PIL image to a PyTorch tensor\n",
        "- We can easily transform it by adding **transform=transforms.ToTensor()** when reading the dataset.\n",
        "- This is given below (just execute)"
      ],
      "id": "8005d75d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d7c8a44"
      },
      "source": [
        "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.ToTensor())"
      ],
      "id": "5d7c8a44",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe65a981"
      },
      "source": [
        "### Step 7: Normalize images\n",
        "- Now you have all images (transformed) in **tensor_cifar10**.\n",
        "- To concatenate a stack of images use **torch.stack(..., dim=3)** on the images\n",
        "    - HINT: Use list comprehension to get a list of images from **tensor_cifar10** (to exclude labels)\n",
        "- Calculate the **mean(dim=1)** by applying it on the stack\n",
        "- Calculate the **std(dim=1)** by applying it on the stack\n",
        "- We will use the results in next step"
      ],
      "id": "fe65a981"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f02d859"
      },
      "source": [
        "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)"
      ],
      "id": "2f02d859",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9707c57",
        "outputId": "ff0d5ed0-2a3e-4a6d-fcd2-8bf69991f076",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imgs.view(3, -1).mean(dim=1)"
      ],
      "id": "c9707c57",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5789d4b3",
        "outputId": "d6572b6d-271e-41d0-e6e2-a4f7d5d931b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imgs.view(3, -1).std(dim=1)"
      ],
      "id": "5789d4b3",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d298703f"
      },
      "source": [
        "### Step 8: Normalize the data\n",
        "- We can add a normalize transform with adding a **transforms.Compose([...])**, where the list will contain the transforms.\n",
        "- The transform we want are **transforms.ToTensor()** and **transforms.Normalize(...)**\n",
        "    - HINT: See lesson how it was done\n",
        "- The **transforms.Normalize(...)** takes two tuples of the results from last step.\n",
        "    - Note: that in the lesson it was single numbers, here we hare tuples.\n",
        "- Read the datasets to **cifar10** with the new transform\n",
        "- Read the validation dataset to **cifar10_val** with the new transform"
      ],
      "id": "d298703f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069a5ea8"
      },
      "source": [
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=False, \n",
        "                           transform=transforms.Compose([\n",
        "                                                         transforms.ToTensor(),\n",
        "                                                         transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                                                                               (0.2470, 0.2435, 0.2616))\n",
        "                           ]))"
      ],
      "id": "069a5ea8",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "037d04db"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=False, \n",
        "                           transform=transforms.Compose([\n",
        "                                                         transforms.ToTensor(),\n",
        "                                                         transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                                                                               (0.2470, 0.2435, 0.2616))\n",
        "                           ]))"
      ],
      "id": "037d04db",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1ef2dcd"
      },
      "source": [
        "### Step 9: Limit the dataset\n",
        "- There are 10 classes in this dataset - to simplify, we will reduce it to two\n",
        "- We will keep label 0 and 2 (**'airplane'** and **'bird'**)\n",
        "- Use list comprehension to filter the datasets.\n",
        "    - To simplify use a **label_map = {0: 0, 2: 1}**, which is used to map label 0 to 0 and label 2 to 1.\n",
        "    - Then use list comprehension **[(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]**\n",
        "    - And similar for **cifar10_val**"
      ],
      "id": "f1ef2dcd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d81727b1"
      },
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
      ],
      "id": "d81727b1",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60bb3eac"
      },
      "source": [
        "### Step 10: Create the model\n",
        "- We create a simple model here\n",
        "    - 3072 input nodes -> Linear with 512 nodes (Tanh acitivation)  -> Linear with 2 nodes (LogSoftmax activation)\n",
        "- To do that use **nn.Sequential(...)** with the following arguments.\n",
        "    - **nn.Linear(3072, 512)**\n",
        "        - Bonus question: Why 3072 input nodes?\n",
        "    - **nn.Tanh()**\n",
        "    - **nn.Linear(512, 2)**\n",
        "    - **nn.LogSoftmax(dim=1)**"
      ],
      "id": "60bb3eac"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a34ddf7"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(3072, 512),\n",
        "                      nn.Tanh(),\n",
        "                      nn.Linear(512, 2),\n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "id": "5a34ddf7",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf32440f"
      },
      "source": [
        "### Step 11: Train the model\n",
        "- Prepare training data\n",
        "\n",
        "```Python\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "```\n",
        "\n",
        "- Set the **learning_rate = 0.01** (to make it easy to adjust)\n",
        "- Prepare optimizer and loss function.\n",
        "\n",
        "```Python\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.NLLLoss()\n",
        "```\n",
        "\n",
        "- Run the training\n",
        "\n",
        "```Python\n",
        "n_epochs = 10\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        outputs = model(imgs.view(batch_size, -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "    \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "```"
      ],
      "id": "cf32440f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0571922e",
        "outputId": "c7a4751b-7b80-4b6c-f1a6-51b5985b01d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 10\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_size = imgs.shape[0]\n",
        "        outputs = model(imgs.view(batch_size, -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n"
      ],
      "id": "0571922e",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.062171\n",
            "Epoch: 1, Loss: 0.163092\n",
            "Epoch: 2, Loss: 0.109265\n",
            "Epoch: 3, Loss: 0.141370\n",
            "Epoch: 4, Loss: 0.173484\n",
            "Epoch: 5, Loss: 0.050794\n",
            "Epoch: 6, Loss: 0.041537\n",
            "Epoch: 7, Loss: 0.053249\n",
            "Epoch: 8, Loss: 0.105814\n",
            "Epoch: 9, Loss: 0.018673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92a127ed"
      },
      "source": [
        "### Step 12: Test the model\n",
        "- Run the following code (where we assume the test data is called **cifar10_val** and the model **model**.\n",
        "```Python\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        batch_size = imgs.shape[0]\n",
        "        outputs = model(imgs.view(batch_size, -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "print(\"Accuracy: %f\", correct / total)\n",
        "```"
      ],
      "id": "92a127ed"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0239d06",
        "outputId": "6d370024-0a6a-4e8d-e2a0-cebc09915326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                       shuffle=False)\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for imgs, labels in val_loader:\n",
        "      batch_size = imgs.shape[0]\n",
        "      outputs = model(imgs.view(batch_size, -1))\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      total += labels.shape[0]\n",
        "      correct += int((predicted == labels).sum())\n",
        "print(\"Accuracy: %f\", correct / total)"
      ],
      "id": "b0239d06",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: %f 0.989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99161df7"
      },
      "source": [
        "### Step 13 (Optional): Improve the model\n",
        "- Try to improve the model\n",
        "    - Simple things you can play with\n",
        "        - Adjust the learning rate\n",
        "        - Run more epochs\n",
        "        - Number of hidden nodes\n",
        "    - Medium things to play with\n",
        "        - Change activation functions\n",
        "        - Add another layer\n",
        "    - Advanced things\n",
        "        - Let your imagination guide you\n",
        "        - For inspiration see state of the art results ([wiki](https://en.wikipedia.org/wiki/CIFAR-10#Research_papers_claiming_state-of-the-art_results_on_CIFAR-10))"
      ],
      "id": "99161df7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37270489"
      },
      "source": [
        ""
      ],
      "id": "37270489",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "281083ed"
      },
      "source": [
        ""
      ],
      "id": "281083ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f103c9c"
      },
      "source": [
        "### Step 14 (Optional): Add more classes\n",
        "- The dataset was limited to two classes (**airplane**s and **bird**s)\n",
        "- Try to add another class (or more) and see how it changes"
      ],
      "id": "0f103c9c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5cad0bf"
      },
      "source": [
        ""
      ],
      "id": "d5cad0bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5d5ffae"
      },
      "source": [
        ""
      ],
      "id": "f5d5ffae",
      "execution_count": null,
      "outputs": []
    }
  ]
}