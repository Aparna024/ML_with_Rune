{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "11 - Lesson - Natural Language Processing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adel-nouar/ML_with_Rune/blob/main/11%20-%20Lesson%20-%20Natural%20Language%20Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba959ea8"
      },
      "source": [
        "# Natural Language Processing\n",
        "### Goal of lesson\n",
        "- How the simple syntax of language can be parsed\n",
        "- What Context-Free Grammar (CFG) is\n",
        "- Use it to parse text\n",
        "- Understand text in trigrams\n",
        "- See how it can be used to generate predictions\n",
        "\n",
        "### What is Natural Language Processing\n",
        "- Automatic computational processing of human languages\n",
        "- Includes \n",
        "    - Algorithms that take human written language as input\n",
        "    - Algorithms that produce natural text\n",
        "\n",
        "- Examples include\n",
        "    - Automatic summarization\n",
        "    - Language identification\n",
        "    - Translation"
      ],
      "id": "ba959ea8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88cafa61"
      },
      "source": [
        "### Syntax\n",
        "- One basic description of a language's syntax is the sequence in which the subject, verb, and object usually appear in sentences.\n",
        "\n",
        "### Formal Grammar\n",
        "- A system of rules for genrating sentences in a language\n",
        "- A grammar is usually thought of as a language generator ([wiki](https://en.wikipedia.org/wiki/Formal_grammar))"
      ],
      "id": "88cafa61"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "338af3bc"
      },
      "source": [
        "### Context-Free Grammar (CFG)\n",
        "- A formal grammar is \"context free\" if its production rules can be applied regardless of the context of a nonterminal ([wiki](https://en.wikipedia.org/wiki/Context-free_grammar))."
      ],
      "id": "338af3bc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eec8e4f6"
      },
      "source": [
        "> #### Programming Notes:\n",
        "> - Libraries used\n",
        ">     - [**nltk**](https://www.nltk.org) - Natural Language Toolkit\n",
        ">     - [**os**](https://docs.python.org/3/library/os.html) Miscellaneous operating system interfaces\n",
        ">     - [**collections**](https://docs.python.org/3/library/collections.html) Container datatypes\n",
        ">     - [**markovify**](https://pypi.org/project/markovify/) A simple, extensible Markov chain generato\n",
        "> - Functionality and concepts used\n",
        ">     - [**ChartParser**](https://tedboy.github.io/nlps/generated/generated/nltk.ChartParser.html) generic chart parser\n",
        ">     - **List Comprehension** to convert data ([Lecture on **List Comprehension**](https://youtu.be/vCYEvtfXdig))\n",
        ">     - [**Counter**](https://docs.python.org/3/library/collections.html#collections.Counter) a dict subclass for counting hashable objects\n",
        ">     - [**markovify.Text**](https://pypi.org/project/markovify/) to create your Markov Model"
      ],
      "id": "eec8e4f6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ea2f28f",
        "outputId": "d0d0e18b-ad1d-422e-e5e9-3950f794deb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "id": "9ea2f28f",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d8eea04"
      },
      "source": [
        "import nltk"
      ],
      "id": "7d8eea04",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06e74e9f",
        "outputId": "dce603be-39f7-4bc4-a724-7cec15df70f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "\n",
        "    NP -> D N | N\n",
        "    VP -> V | V NP\n",
        "\n",
        "    D -> \"the\" | \"a\"\n",
        "    N -> \"she\" | \"city\" | \"car\"\n",
        "    V -> \"saw\" | \"walked\"    \n",
        "\"\"\")\n",
        "\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "sentence = input().split()\n",
        "\n",
        "for tree in parser.parse(sentence):\n",
        "  tree.pretty_print()\n"
      ],
      "id": "06e74e9f",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "she saw a car\n",
            "         S             \n",
            "  _______|___           \n",
            " |           VP        \n",
            " |    _______|___       \n",
            " NP  |           NP    \n",
            " |   |        ___|___   \n",
            " N   V       D       N \n",
            " |   |       |       |  \n",
            "she saw      a      car\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6fa8235"
      },
      "source": [
        "### Challenge with CFG\n",
        "- You need to encode all possibilities\n",
        "\n",
        "### Idea\n",
        "- Understand text in small subsets\n",
        "- **$n$-gram**\n",
        "    - a contiguous sequence of $n$ items from a sample text\n",
        "- **Word $n$-gram**\n",
        "    - a contiguous sequence of $n$ words from a sample text\n",
        "- **unigram**\n",
        "    - 1 items in sequence\n",
        "- **bigram**\n",
        "    - 2 items in sequence\n",
        "- **trigram**\n",
        "    - 3 items in sequence"
      ],
      "id": "b6fa8235"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30889d25"
      },
      "source": [
        "### Word Tokenization\n",
        "- the task of splitting a sequence of words into tokens\n",
        "\n",
        "- Considerations: comma, punktuation, etc."
      ],
      "id": "30889d25"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ea65e3"
      },
      "source": [
        "import os\n",
        "from collections import Counter"
      ],
      "id": "d4ea65e3",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3d5f1b8",
        "outputId": "89e0f9f8-29f0-497e-e658-dcb7e0b54764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "id": "d3d5f1b8",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be1f0f82",
        "outputId": "cac2ec4d-d979-4d40-fdda-02a66dedc7be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "content = []\n",
        "for filename in os.listdir('holmes/'):\n",
        "    with open(f'holmes/{filename}') as f:\n",
        "        content.append(f.read())"
      ],
      "id": "be1f0f82",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e435e252e841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'files/holmes/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'files/holmes/{filename}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'files/holmes/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fcdbe57"
      },
      "source": [
        ""
      ],
      "id": "7fcdbe57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a58c7ddd"
      },
      "source": [
        ""
      ],
      "id": "a58c7ddd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79dc5211"
      },
      "source": [
        ""
      ],
      "id": "79dc5211",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9b296ab"
      },
      "source": [
        ""
      ],
      "id": "d9b296ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "087dc954"
      },
      "source": [
        ""
      ],
      "id": "087dc954",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1373e8d6"
      },
      "source": [
        "### Markov Model\n",
        "- A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous even ([wiki](https://en.wikipedia.org/wiki/Markov_chain))\n",
        "- Or as the example above:\n",
        "    - Given any two words -> you have probabilities for the next word"
      ],
      "id": "1373e8d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c260c02b"
      },
      "source": [
        ""
      ],
      "id": "c260c02b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3e9fc8c"
      },
      "source": [
        ""
      ],
      "id": "c3e9fc8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "354f2d51"
      },
      "source": [
        ""
      ],
      "id": "354f2d51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f76620f"
      },
      "source": [
        ""
      ],
      "id": "4f76620f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e40aba96"
      },
      "source": [
        ""
      ],
      "id": "e40aba96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a9923ab"
      },
      "source": [
        ""
      ],
      "id": "2a9923ab",
      "execution_count": null,
      "outputs": []
    }
  ]
}